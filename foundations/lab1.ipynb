{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fccfa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843809f",
   "metadata": {},
   "source": [
    "Setting up the gemini api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caed7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is not set. Please set it to your Gemini API key.\")\n",
    "else:\n",
    "    print(\"GEMINI_API_KEY is set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04c9b2",
   "metadata": {},
   "source": [
    "Import the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a88e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "521e6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "contents = [m[\"content\"] for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "348f0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Paris\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "     contents=contents,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "        temperature=0.2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 4) Grab the generated text\n",
    "print(\"Response:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2a48884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Question: Imagine a universe where the fundamental forces are reversed in strength.  Describe three likely consequences of this change on the formation and evolution of stars, and explain your reasoning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    contents=[m[\"content\"] for m in messages],\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "        temperature=0.2,\n",
    "    ),\n",
    ")\n",
    "# 5) Print the generated question\n",
    "print(\"Generated Question:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202df97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to the Question: Devise a system for fairly distributing a limited resource (e.g., food, medicine, housing) among a population with diverse needs and competing priorities, considering both short-term relief and long-term sustainability.  Explain the principles guiding your system and how it addresses potential challenges like corruption, changing demographics, and unforeseen circumstances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    contents=[m[\"content\"] for m in messages],\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "        temperature=0.2,\n",
    "    ),\n",
    ")\n",
    "# 6) Print the answer to the question\n",
    "print(\"Answer to the Question:\", response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8d68e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Devise a system for fairly distributing a limited resource (e.g., food, medicine, housing) among a population with diverse needs and competing priorities, considering both short-term relief and long-term sustainability.  Explain the principles guiding your system and how it addresses potential challenges like corruption, changing demographics, and unforeseen circumstances.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40196e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Business Area: **Personalized Education and Tutoring:**\n",
      "\n",
      "Agentic AI has the potential to revolutionize education by creating personalized learning experiences tailored to individual student needs and learning styles. An AI agent could act as a personalized tutor, providing customized curriculum, real-time feedback, and adaptive learning paths.  It could assess a student's strengths and weaknesses, identify knowledge gaps, and adjust the learning material and pace accordingly.  This goes beyond simply recommending existing content; the agent could generate new, personalized exercises, explanations, and even motivational strategies. This has high potential because of the increasing demand for personalized learning and the limitations of current one-size-fits-all educational models.\n",
      "✅ Pain-Point: A major pain point in personalized education and tutoring is the **lack of scalability and affordability of high-quality, individualized instruction.**  Currently, truly personalized learning experiences often require one-on-one human tutoring, which is expensive and resource-intensive, making it inaccessible to most students.  This creates an inequitable learning environment where students with greater financial resources have access to personalized support, while others are left to struggle with standardized approaches that may not effectively address their individual needs.\n",
      "\n",
      "Agentic AI can address this pain point by providing **scalable and affordable personalized tutoring** to a large number of students simultaneously.  An AI tutor doesn't experience fatigue, can work 24/7, and can be deployed to countless students at a fraction of the cost of human tutors. This democratizes access to personalized learning, providing every student with the opportunity to benefit from customized instruction, targeted feedback, and adaptive learning paths, regardless of their socioeconomic background.\n",
      "✅ Proposed Agentic AI Solution: ## Agentic AI Solution: Personalized Learning Companion (PLC)\n",
      "\n",
      "The Personalized Learning Companion (PLC) is an agentic AI system designed to provide scalable and affordable personalized tutoring.  It leverages several key AI technologies to deliver a customized learning experience:\n",
      "\n",
      "**1. Knowledge Representation and Reasoning:**\n",
      "\n",
      "* **Curriculum Mapping:** PLC ingests and understands K-12 curriculum standards across various subjects, creating a comprehensive knowledge graph. This allows it to pinpoint a student's current knowledge level and identify learning gaps.\n",
      "* **Adaptive Learning Paths:** Based on the student's individual learning style, pace, and identified gaps, PLC dynamically generates personalized learning paths. These paths adapt in real-time based on student performance and provide targeted learning resources.\n",
      "\n",
      "**2. Natural Language Processing (NLP) and Generation (NLG):**\n",
      "\n",
      "* **Interactive Tutoring:** PLC engages students in natural language conversations, explaining concepts, answering questions, and providing hints. It can understand complex questions and provide tailored\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1) Load your .env so GOOGLE_API_KEY is populated\n",
    "load_dotenv()\n",
    "\n",
    "# 2) Instantiate the Gemini client\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# 3) Common config for all three calls\n",
    "config = types.GenerateContentConfig(\n",
    "    max_output_tokens=200,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Step 1: Pick a business area\n",
    "resp1 = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    contents=\"List one high-potential business area ripe for an Agentic AI opportunity.\",\n",
    "    config=config,\n",
    ")\n",
    "business_area = resp1.text.strip()\n",
    "print(\"✅ Business Area:\", business_area)\n",
    "\n",
    "# Step 2: Identify a key pain-point\n",
    "resp2 = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    contents=(\n",
    "        f\"In the **{business_area}** sector, describe a major pain-point \"\n",
    "        \"that an Agentic AI solution could address.\"\n",
    "    ),\n",
    "    config=config,\n",
    ")\n",
    "pain_point = resp2.text.strip()\n",
    "print(\"✅ Pain-Point:\", pain_point)\n",
    "\n",
    "# Step 3: Propose an Agentic AI solution\n",
    "resp3 = client.models.generate_content(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    contents=(\n",
    "        f\"Given the pain-point **{pain_point}**, propose a concrete \"\n",
    "        \"Agentic AI solution to solve it.\"\n",
    "    ),\n",
    "    config=config,\n",
    ")\n",
    "solution = resp3.text.strip()\n",
    "print(\"✅ Proposed Agentic AI Solution:\", solution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

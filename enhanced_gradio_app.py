#!/usr/bin/env python3
"""
Enhanced AI Career Assistant with Gradio UI
Comprehensive dashboard with enhanced routing, AI-powered responses, and production-ready features.
Ready for deployment to Render or other cloud platforms.
"""
import gradio as gr
import asyncio
import logging
import os
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime, timedelta
import json
import time
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add foundations to path
foundations_path = Path(__file__).parent / "foundations"
sys.path.insert(0, str(foundations_path))

# Import enhanced components
try:
    from foundations.enhanced_smart_router import EnhancedMultiAgentRouter
    from foundations.simple_mcp_client import create_simple_mcp_client
    ENHANCED_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Enhanced components not available: {e}")
    ENHANCED_AVAILABLE = False

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('enhanced_assistant.log')
    ]
)
logger = logging.getLogger(__name__)

# --- Configuration ---
RESUME_PATH = "agent_knowledge/venkatesh_narra_resume.pdf"
CALENDLY_LINK = "https://calendly.com/venkynarra"

# Create beautiful theme
theme = gr.themes.Soft(
    primary_hue="purple",
    secondary_hue="blue",
    neutral_hue="gray",
    font=[gr.themes.GoogleFont("Poppins"), "ui-sans-serif", "system-ui", "sans-serif"]
)

# Custom CSS for enhanced UI
custom_css = """
.gradio-container {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    font-family: 'Poppins', sans-serif;
}

.main-container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

.chat-interface {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.metric-card {
    background: rgba(255, 255, 255, 0.15);
    border-radius: 10px;
    padding: 15px;
    margin: 5px;
    backdrop-filter: blur(5px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.profile-section {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 20px;
    margin: 10px 0;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.button-primary {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    color: white;
    font-weight: 600;
    transition: all 0.3s ease;
}

.button-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 5px 15px rgba(0,0,0,0.3);
}

.contact-form {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 20px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.chart-container {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 20px;
    margin: 10px 0;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.footer {
    text-align: center;
    padding: 20px;
    color: rgba(255, 255, 255, 0.8);
    font-size: 14px;
}

.tabs {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.tab-nav {
    background: rgba(255, 255, 255, 0.05);
    border-radius: 10px;
    padding: 5px;
}

.tab-nav button {
    background: transparent;
    border: none;
    color: rgba(255, 255, 255, 0.8);
    font-weight: 500;
    transition: all 0.3s ease;
}

.tab-nav button.selected {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border-radius: 8px;
}
"""

# Static data for profile display
PROFILE_DATA = {
    "name": "Venkatesh Narra",
    "title": "Software Development Engineer",
    "company": "Veritis Group Inc",
    "location": "Virginia, USA",
    "email": "vnarrag@gmu.edu",
    "phone": "+1 703-453-2157",
    "linkedin": "https://www.linkedin.com/in/venkateswara-narra-91170b34a",
    "github": "https://github.com/venkynarra",
    "calendly": CALENDLY_LINK,
    
    "skills": {
        "programming": ["Python", "Java", "JavaScript", "TypeScript", "C++", "SQL"],
        "ai_ml": ["TensorFlow", "PyTorch", "Scikit-learn", "OpenCV", "Transformers", "LangChain"],
        "web": ["React", "Angular", "Vue.js", "Node.js", "Express.js", "FastAPI", "Django"],
        "cloud": ["AWS", "Google Cloud", "Azure", "Docker", "Kubernetes", "Redis"],
        "databases": ["PostgreSQL", "MongoDB", "MySQL", "Redis", "Elasticsearch"],
        "tools": ["Git", "Jenkins", "Jira", "Postman", "Figma", "Linux"]
    },
    
    "projects": [
        {
            "name": "AI Career Assistant",
            "description": "Intelligent career guidance system with RAG architecture",
            "technologies": ["Python", "LangChain", "Pinecone", "Gradio", "Gemini AI"],
            "features": ["Sub-2s response times", "Vector search", "Multi-modal chat", "Analytics dashboard"]
        },
        {
            "name": "Clinical Data Processing Platform",
            "description": "HIPAA-compliant medical data processing system",
            "technologies": ["Python", "FastAPI", "PostgreSQL", "Docker", "AWS"],
            "features": ["Real-time processing", "Automated workflows", "Compliance monitoring", "Analytics"]
        },
        {
            "name": "Multi-Modal Chat Platform",
            "description": "Advanced chat system with AI-powered responses",
            "technologies": ["React", "Node.js", "Socket.io", "TensorFlow", "Redis"],
            "features": ["Real-time messaging", "AI integration", "File sharing", "Voice/video calls"]
        }
    ]
}

# Enhanced response system for better quality
class EnhancedResponseGenerator:
    def __init__(self):
        # Import AI components
        try:
            from llama_index.llms.gemini import Gemini
            from foundations.config import GEMINI_API_KEY
            self.llm = Gemini(model_name="gemini-1.5-flash", api_key=GEMINI_API_KEY)
            self.ai_available = True
        except ImportError:
            self.llm = None
            self.ai_available = False
        
        # Concise context data for AI generation (NOT static responses)
        self.context_data = {
            "skills": {
                "programming": ["Python (Expert, 4+ years)", "Java (Advanced, 3+ years)", "JavaScript/TypeScript (Advanced, 3+ years)", "C++ (Intermediate, 2+ years)", "SQL (Advanced, 4+ years)"],
                "ai_ml": ["TensorFlow", "PyTorch", "Scikit-learn", "OpenCV", "LangChain", "Transformers", "Google Gemini"],
                "web": ["React", "Angular", "Vue.js", "Node.js", "Express.js", "FastAPI", "Django", "Spring Boot"],
                "cloud": ["AWS", "Docker", "Kubernetes", "PostgreSQL", "MongoDB", "Redis", "CI/CD", "Microservices"]
            },
            "experience": {
                "current": "Software Development Engineer at Veritis Group Inc (2024-Present)",
                "focus": "AI testing agents, clinical API systems, 25K+ daily inferences, 99.9% uptime",
                "achievements": ["80% reduction in manual testing", "60% API optimization", "Real-time systems with 1000+ concurrent users"]
            },
            "education": {
                "masters": "MS Computer Science, George Mason University (2024, GPA: 3.8/4.0)",
                "bachelors": "BTech Computer Science, GITAM Deemed University (2021, GPA: 3.7/4.0)",
                "specialization": "AI/ML systems, computer vision, software engineering"
            },
            "projects": ["AI Career Assistant (RAG-based)", "Clinical Data Platform (HIPAA-compliant)", "Multi-Modal Chat Platform", "Computer Vision System", "E-commerce Platform"],
            "contact": {
                "email": "vnarrag@gmu.edu",
                "phone": "+1 703-453-2157",
                "linkedin": "https://www.linkedin.com/in/venkateswara-narra-91170b34a",
                "github": "https://github.com/venkynarra"
            }
        }
    
    async def generate_enhanced_response(self, query: str, context: str = "") -> str:
        """Generate dynamic AI responses instead of static templates."""
        if not self.ai_available:
            return self._generate_fallback_response(query)
        
        # Determine query type and relevant context
        query_type = self._classify_query(query)
        relevant_context = self._get_relevant_context(query_type)
        
        # Create dynamic prompt for AI
        prompt = self._create_dynamic_prompt(query, query_type, relevant_context)
        
        try:
            # Use AI to generate contextual response
            response = await self.llm.acomplete(prompt)
            
            # Extract clean response
            if hasattr(response, 'text'):
                clean_response = response.text
            elif hasattr(response, 'content'):
                clean_response = response.content
            else:
                clean_response = str(response).strip('[]"\'').strip()
            
            return clean_response
            
        except Exception as e:
            logger.warning(f"AI generation failed: {e}")
            return self._generate_fallback_response(query)
    
    def _classify_query(self, query: str) -> str:
        """Classify query type for appropriate context."""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['skill', 'technology', 'programming', 'framework']):
            return 'skills'
        elif any(word in query_lower for word in ['experience', 'work', 'job', 'career']):
            return 'experience'
        elif any(word in query_lower for word in ['education', 'degree', 'university', 'study']):
            return 'education'
        elif any(word in query_lower for word in ['project', 'portfolio', 'built', 'created']):
            return 'projects'
        elif any(word in query_lower for word in ['contact', 'email', 'phone', 'reach']):
            return 'contact'
        else:
            return 'general'
    
    def _get_relevant_context(self, query_type: str) -> str:
        """Get relevant context data for the query type."""
        if query_type == 'skills':
            return f"""
Skills Overview:
- Programming: {', '.join(self.context_data['skills']['programming'])}
- AI/ML: {', '.join(self.context_data['skills']['ai_ml'])}
- Web Development: {', '.join(self.context_data['skills']['web'])}
- Cloud & DevOps: {', '.join(self.context_data['skills']['cloud'])}
"""
        elif query_type == 'experience':
            exp = self.context_data['experience']
            return f"""
Experience:
- Current: {exp['current']}
- Focus: {exp['focus']}
- Achievements: {', '.join(exp['achievements'])}
"""
        elif query_type == 'education':
            edu = self.context_data['education']
            return f"""
Education:
- Masters: {edu['masters']}
- Bachelors: {edu['bachelors']}
- Specialization: {edu['specialization']}
"""
        elif query_type == 'projects':
            return f"""
Key Projects: {', '.join(self.context_data['projects'])}
"""
        elif query_type == 'contact':
            contact = self.context_data['contact']
            return f"""
Contact Information:
- Email: {contact['email']}
- Phone: {contact['phone']}
- LinkedIn: {contact['linkedin']}
- GitHub: {contact['github']}
"""
        else:
            return "Comprehensive background in AI/ML engineering and full-stack development with 4+ years of experience."
    
    def _create_dynamic_prompt(self, query: str, query_type: str, context: str) -> str:
        """Create dynamic prompt for AI generation."""
        return f"""You are Venkatesh Narra, a skilled Software Development Engineer with 4+ years of experience. 

Query: "{query}"

Your Background:
{context}

Instructions:
1. Provide a conversational, engaging response that directly answers the question
2. Use specific details from your background when relevant
3. Keep response concise (100-200 words) unless more detail is specifically requested
4. Be professional yet personable
5. Don't use overly long bullet point lists - focus on the most relevant information
6. Think about what the user really wants to know and answer that specifically
7. Include a call-to-action or next step if appropriate

Generate a natural, contextual response:"""
    
    def _generate_fallback_response(self, query: str) -> str:
        """Generate simple fallback response when AI is not available."""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['skill', 'technology', 'programming']):
            return "I'm proficient in Python, Java, JavaScript, and have extensive experience with AI/ML frameworks like TensorFlow and PyTorch, as well as cloud technologies like AWS and Docker."
        elif any(word in query_lower for word in ['experience', 'work']):
            return "I'm currently a Software Development Engineer at Veritis Group Inc, where I've built AI testing agents and clinical APIs processing 25,000+ daily inferences with 99.9% uptime."
        elif any(word in query_lower for word in ['education', 'degree']):
            return "I have an MS in Computer Science from George Mason University (2024, GPA: 3.8) and a BTech from GITAM Deemed University (2021, GPA: 3.7)."
        elif any(word in query_lower for word in ['contact', 'email']):
            return "You can reach me at vnarrag@gmu.edu or +1 703-453-2157. I'm also on LinkedIn and GitHub."
        else:
            return "I'm Venkatesh Narra, a Software Development Engineer with 4+ years of experience in AI/ML and full-stack development. Feel free to ask me about my skills, experience, or projects!"

# Create global instance
response_generator = EnhancedResponseGenerator()

# Performance tracking
class EnhancedCareerAssistant:
    def __init__(self):
        self.router = None
        self.mcp_client = None
        self.stats = {
            "total_queries": 0,
            "successful_queries": 0,
            "avg_response_time": 0.0,
            "query_types": {
                "technical": 0,
                "experience": 0,
                "projects": 0,
                "other": 0
            }
        }
        
        # Enhanced session statistics tracking from run_app.py
        self.session_stats = {
            "total_queries": 0,
            "fast_queries": 0,  # < 2 seconds
            "slow_queries": 0,  # >= 2 seconds
            "avg_response_time": 0.0,
            "query_types": {}
        }
    
    def get_performance_stats(self):
        """Get comprehensive performance statistics."""
        fast_response_rate = 0
        if self.session_stats["total_queries"] > 0:
            fast_response_rate = (self.session_stats["fast_queries"] / self.session_stats["total_queries"]) * 100
        
        return {
            "total_queries": self.session_stats["total_queries"],
            "fast_queries": self.session_stats["fast_queries"],
            "slow_queries": self.session_stats["slow_queries"],
            "avg_response_time": self.session_stats["avg_response_time"],
            "fast_response_rate": fast_response_rate,
            "query_types": self.session_stats["query_types"]
        }

    async def initialize(self):
        """Initialize the enhanced career assistant with multi-agent coordination."""
        logger.info("üöÄ Initializing Enhanced Career Assistant...")
        logger.info("ü§ñ Multi-Agent System Architecture:")
        logger.info("   1. Enhanced Smart Router (Gemini AI + Vector DB + Cache)")
        logger.info("   2. MCP Agent (gRPC Career Assistant Server)")
        logger.info("   3. Enhanced Knowledge Base (Fallback Agent)")
        
        # Initialize Enhanced Smart Router (Primary AI Agent)
        if ENHANCED_AVAILABLE:
            try:
                logger.info("üîß Initializing Enhanced Smart Router...")
                self.router = EnhancedMultiAgentRouter()
                await self.router.initialize()
                logger.info("‚úÖ Enhanced Smart Router initialized")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Enhanced router initialization failed: {e}")
                self.router = None
        else:
            logger.info("‚ö†Ô∏è Enhanced components not available, using fallback mode")
            self.router = None
        
        # Initialize MCP Agent (Secondary Structured Agent)
        try:
            logger.info("üîß Initializing MCP Agent (gRPC Server)...")
            
            # Try to start MCP server if not running
            await self._ensure_mcp_server_running()
            
            # Initialize MCP client
            self.mcp_client = await create_simple_mcp_client("career_assistant")
            logger.info("‚úÖ MCP Agent initialized successfully")
            
            # Test MCP connection
            try:
                test_response = await self._test_mcp_connection()
                if test_response:
                    logger.info("‚úÖ MCP Agent connection verified")
                else:
                    logger.warning("‚ö†Ô∏è MCP Agent connection test failed")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è MCP Agent connection test error: {e}")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è MCP agent initialization failed: {e}")
            self.mcp_client = None
        
        # Report agent availability
        available_agents = []
        if self.router:
            available_agents.append("Enhanced Smart Router")
        if self.mcp_client:
            available_agents.append("MCP Agent")
        available_agents.append("Enhanced Knowledge Base")  # Always available
        
        logger.info(f"üéØ Available Agents: {', '.join(available_agents)}")
        logger.info(f"üìä Total Agent Count: {len(available_agents)}")
        
        if len(available_agents) >= 2:
            logger.info("üöÄ Multi-agent system ready for intelligent routing!")
        else:
            logger.info("üîÑ Running in fallback mode with knowledge base only")

    async def process_query(self, query: str) -> Dict[str, Any]:
        """Process user query with enhanced response generation and multi-agent coordination."""
        start_time = time.time()
        agent_attempts = []
        
        try:
            # Analyze query to determine best agent
            query_type = self._classify_query_for_routing(query)
            logger.info(f"üéØ Query classified as: {query_type}")
            
            # Step 1: Try Enhanced Smart Router first (best for complex AI tasks)
            if self.router and query_type in ['complex', 'ai_technical', 'general']:
                try:
                    logger.info(f"üöÄ Processing via Enhanced Smart Router: {query}")
                    agent_attempts.append("Enhanced Router")
                    response = await self.router.route_query(query)
                    if response and len(response.strip()) > 50:  # Valid response
                        processing_time = (time.time() - start_time) * 1000
                        self._update_stats(query, processing_time, True)
                        return {
                            "response": response,
                            "source": "Enhanced Router + AI Agents",
                            "processing_time": processing_time,
                            "agent_path": " ‚Üí ".join(agent_attempts)
                        }
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Enhanced router failed: {e}")
            
            # Step 2: Try MCP Agent for structured queries (best for contact, resume, specific info)
            if self.mcp_client and query_type in ['contact', 'resume', 'structured', 'general']:
                try:
                    logger.info(f"üîß Processing via MCP Agent: {query}")
                    agent_attempts.append("MCP Agent")
                    mcp_response = await self._process_via_mcp(query)
                    if mcp_response and len(mcp_response.strip()) > 30:
                        processing_time = (time.time() - start_time) * 1000
                        self._update_stats(query, processing_time, True)
                        return {
                            "response": mcp_response,
                            "source": "MCP Agent (gRPC)",
                            "processing_time": processing_time,
                            "agent_path": " ‚Üí ".join(agent_attempts)
                        }
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è MCP agent failed: {e}")
            
            # Step 3: Enhanced Knowledge Base (always available fallback)
            logger.info(f"üìö Processing via Enhanced Knowledge Base: {query}")
            agent_attempts.append("Knowledge Base")
            response = await response_generator.generate_enhanced_response(query)
            processing_time = (time.time() - start_time) * 1000
            
            self._update_stats(query, processing_time, True)
            return {
                "response": response,
                "source": "Enhanced Knowledge Base",
                "processing_time": processing_time,
                "agent_path": " ‚Üí ".join(agent_attempts)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Query processing failed: {e}")
            processing_time = (time.time() - start_time) * 1000
            self._update_stats(query, processing_time, False)
            return {
                "response": "I apologize, but I encountered an error processing your query. Please try again or rephrase your question.",
                "source": "Error Handler",
                "processing_time": processing_time,
                "agent_path": " ‚Üí ".join(agent_attempts + ["Error Handler"])
            }

    def _classify_query_for_routing(self, query: str) -> str:
        """Classify query to determine the best agent for processing."""
        query_lower = query.lower()
        
        # Contact/Resume queries - best for MCP Agent
        if any(word in query_lower for word in ['contact', 'email', 'phone', 'reach', 'resume', 'cv', 'download']):
            return 'contact'
        
        # Technical skills/frameworks queries - best for MCP Agent (structured data)
        if any(phrase in query_lower for phrase in ['frameworks', 'technologies', 'tools', 'languages', 'programming']):
            return 'structured'
        
        # Education/experience/skills queries - good for MCP Agent
        if any(word in query_lower for word in ['education', 'experience', 'skills', 'projects', 'portfolio', 'background']):
            return 'structured'
        
        # Complex explanatory queries - best for Enhanced Router
        if any(phrase in query_lower for phrase in ['explain how', 'how does', 'what is the difference', 'tell me about the process', 'describe the architecture']):
            return 'complex'
        
        # Technical AI/ML concepts - best for Enhanced Router
        if any(word in query_lower for word in ['algorithm', 'architecture', 'model', 'training', 'deployment']) and not any(word in query_lower for word in ['frameworks', 'tools', 'use']):
            return 'ai_technical'
        
        # General queries - try all agents
        return 'general'

    def _update_stats(self, query: str, response_time: float, is_successful: bool):
        """Update query statistics with enhanced tracking from run_app.py."""
        # Update basic stats
        self.stats["total_queries"] += 1
        if is_successful:
            self.stats["successful_queries"] += 1
            
        self.stats["avg_response_time"] = (
            (self.stats["avg_response_time"] * (self.stats["total_queries"] - 1) + response_time) 
            / self.stats["total_queries"]
        )
        
        # Classify query type
        query_lower = query.lower()
        if any(word in query_lower for word in ['skill', 'technology', 'programming']):
            self.stats["query_types"]["technical"] += 1
        elif any(word in query_lower for word in ['experience', 'work', 'job']):
            self.stats["query_types"]["experience"] += 1
        elif any(word in query_lower for word in ['project', 'portfolio', 'built']):
            self.stats["query_types"]["projects"] += 1
        else:
            self.stats["query_types"]["other"] += 1
        
        # Enhanced session stats tracking from run_app.py
        self.session_stats['total_queries'] += 1
        if response_time < 2000:  # Fast response < 2 seconds
            self.session_stats['fast_queries'] += 1
        else:
            self.session_stats['slow_queries'] += 1
        
        # Calculate running average for session stats
        total_time = self.session_stats['avg_response_time'] * (self.session_stats['total_queries'] - 1)
        self.session_stats['avg_response_time'] = (total_time + response_time) / self.session_stats['total_queries']
        
        # Track detailed query types for session stats
        detailed_query_type = self._classify_query_for_routing(query)
        self.session_stats['query_types'][detailed_query_type] = self.session_stats['query_types'].get(detailed_query_type, 0) + 1

    async def _process_via_mcp(self, query: str) -> str:
        """Process query through MCP agent with career-specific routing."""
        try:
            # Route different query types to appropriate MCP methods
            query_lower = query.lower()
            
            if any(word in query_lower for word in ['contact', 'email', 'phone', 'reach']):
                # Get contact information via MCP
                if hasattr(self.mcp_client, 'get_contact_info'):
                    try:
                        contact_info = await self.mcp_client.get_contact_info()
                        return contact_info
                    except:
                        pass
                
                # Fallback contact response
                return f"""Here's my contact information:
                
üìß **Email**: vnarrag@gmu.edu
üì± **Phone**: +1 703-453-2157
üíº **LinkedIn**: https://www.linkedin.com/in/venkatesh-narra-profile/
üîó **GitHub**: https://github.com/venkynarra/Portfolio
üìÖ **Schedule Meeting**: https://calendly.com/venkynarra

Feel free to reach out through any of these channels. I'm always open to discussing new opportunities, collaborations, or technical challenges!"""

            elif any(word in query_lower for word in ['resume', 'cv', 'download']):
                # Provide resume information via MCP
                if hasattr(self.mcp_client, 'get_resume_info'):
                    try:
                        resume_info = await self.mcp_client.get_resume_info()
                        return resume_info
                    except:
                        pass
                
                # Fallback resume response
                return """You can download my resume directly from the sidebar using the "üìÑ Download Resume" button, or I can provide a summary of my key qualifications:

üéì **Education**: MS in Computer Science, George Mason University (2024)
üíº **Experience**: 4+ years in AI/ML and Full-Stack Development  
üöÄ **Current Role**: Software Development Engineer at Veritis Group Inc
üõ†Ô∏è **Key Skills**: Python, AI/ML, Cloud Architecture, Full-Stack Development
üìä **Achievements**: 25K+ daily API inferences, 99.9% uptime systems

Would you like me to elaborate on any specific aspect of my background?"""

            elif any(word in query_lower for word in ['project', 'portfolio', 'work', 'built']):
                # Get project information via MCP
                if hasattr(self.mcp_client, 'get_projects'):
                    try:
                        projects = await self.mcp_client.get_projects()
                        return projects
                    except:
                        pass
                
                # Fallback to AI-generated response
                return await response_generator.generate_enhanced_response(query)

            else:
                # General career query processing via MCP
                if hasattr(self.mcp_client, 'process_career_query'):
                    try:
                        return await self.mcp_client.process_career_query(query)
                    except:
                        pass
                
                # Fallback to AI-generated response
                return await response_generator.generate_enhanced_response(query)
                
        except Exception as e:
            logger.warning(f"MCP processing failed: {e}")
            # Fallback to AI-generated response
            return await response_generator.generate_enhanced_response(query)

    def get_analytics_data(self) -> Dict[str, Any]:
        """Get analytics data for dashboard."""
        total_queries = self.stats["total_queries"]
        successful_queries = self.stats.get("successful_queries", total_queries)
        success_rate = (successful_queries / max(total_queries, 1)) * 100
        
        return {
            "total_queries": total_queries,
            "avg_response_time": round(self.stats["avg_response_time"], 2),
            "query_distribution": self.stats["query_types"],
            "success_rate": round(success_rate, 1),
            "uptime": "99.9%",  # Static for now, could be calculated from start time
            "performance_trend": [
                {"time": f"Hour {i}", "response_time": max(500, self.stats["avg_response_time"] + (i * 50 - 100))}
                for i in range(24)
            ],
            "agent_status": {
                "enhanced_router": self.router is not None,
                "mcp_agent": self.mcp_client is not None,
                "knowledge_base": True
            }
        }

    async def _ensure_mcp_server_running(self):
        """Ensures the MCP server is running and returns its process."""
        # This is a placeholder. In a real scenario, you'd check if a process is already running
        # and start it if not. For simplicity, we'll just log the attempt.
        logger.info("Attempting to start MCP server (placeholder)...")
        # In a production environment, you'd start a subprocess here:
        # import subprocess
        # self.mcp_server_process = subprocess.Popen(["python", "mcp_server.py"])
        # logger.info(f"MCP server process started with PID: {self.mcp_server_process.pid}")
        # For now, we'll just return a dummy process if not running
        return None # Placeholder for actual process

    async def _test_mcp_connection(self):
        """Tests if the MCP server is responding."""
        if self.mcp_client:
            try:
                # Attempt to make a simple request to the MCP server
                # This is a basic check, a more robust test might involve a specific endpoint
                test_response = await self.mcp_client.get_contact_info()
                if "üìß Email" in test_response or "üìÖ Schedule Meeting" in test_response:
                    return True
                else:
                    logger.warning(f"MCP server test response: {test_response}")
                    return False
            except Exception as e:
                logger.warning(f"MCP server connection test error: {e}")
                return False
        return False
    
    async def get_performance_stats(self) -> Dict[str, Any]:
        """Get comprehensive performance statistics from run_app.py."""
        if self.router and hasattr(self.router, 'get_performance_stats'):
            try:
                return await self.router.get_performance_stats()
            except:
                pass
        
        # Return session stats as fallback
        stats = self.session_stats
        uptime = datetime.now() - stats['session_start']
        
        return {
            'total_queries': stats['total_queries'],
            'avg_response_time_ms': stats['avg_response_time'],
            'sub_2s_rate': stats['fast_queries'] / max(stats['total_queries'], 1),
            'cache_hit_rate': 0.0,  # Not available in fallback
            'uptime_seconds': uptime.total_seconds(),
            'query_types': stats['query_types']
        }
    
    async def shutdown(self):
        """Shutdown the assistant gracefully (from run_app.py)."""
        logger.info("üîå Shutting down Enhanced AI Assistant...")
        
        if self.router and hasattr(self.router, 'close'):
            try:
                await self.router.close()
                logger.info("‚úÖ Enhanced Smart Router closed")
            except Exception as e:
                logger.error(f"Error closing router: {e}")
        
        if self.mcp_client and hasattr(self.mcp_client, 'close'):
            try:
                self.mcp_client.close()
                logger.info("‚úÖ Simple MCP Client closed")
            except Exception as e:
                logger.error(f"Error closing MCP client: {e}")
        
        logger.info("üéâ Shutdown complete!")

# Initialize assistant
assistant = EnhancedCareerAssistant()

# --- UI Components ---

def get_base64_encoded_image(image_path):
    """Encode image to base64."""
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except FileNotFoundError:
        return None

def create_resume_download_button():
    """Create download button for resume."""
    if os.path.exists(RESUME_PATH):
        return gr.File(
            value=RESUME_PATH,
            label="üìÑ Download Resume",
            visible=True
        )
    else:
        return gr.HTML(
            value="<div style='text-align: center; color: #ff6b6b;'>‚ùå Resume file not found</div>",
            visible=True
        )

async def chat_interface(message, history):
    """Enhanced chat interface with multi-agent processing."""
    if not message.strip():
        return history, ""
    
    # Add user message to history
    history = history or []
    history.append({"role": "user", "content": message})
    
    try:
        # Process query with multi-agent coordination
        result = await assistant.process_query(message)
        
        # Add clean response to history without metadata
        history.append({"role": "assistant", "content": result['response']})
        
    except Exception as e:
        logger.error(f"Chat error: {e}")
        error_response = "Sorry, I encountered an error processing your query. Please try again."
        
        history.append({"role": "assistant", "content": error_response})
    
    return history, ""

def create_analytics_chart():
    """Create analytics chart for dashboard."""
    analytics = assistant.get_analytics_data()
    
    # Query distribution pie chart
    query_data = analytics["query_distribution"]
    if any(query_data.values()):
        fig = px.pie(
            values=list(query_data.values()),
            names=list(query_data.keys()),
            title="Query Distribution",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig.update_traces(
            textposition='inside',
            textinfo='percent+label'
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(color='white')
        )
    else:
        fig = go.Figure()
        fig.add_annotation(
            text="No queries yet",
            xref="paper", yref="paper",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=20, color='white')
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
        )
    
    return fig

def create_performance_chart():
    """Create performance chart for dashboard."""
    analytics = assistant.get_analytics_data()
    
    # Performance trend line chart
    trend_data = analytics["performance_trend"]
    if trend_data:
        fig = px.line(
            x=[item["time"] for item in trend_data],
            y=[item["response_time"] for item in trend_data],
            title="Response Time Trend (24h)",
            labels={'x': 'Time', 'y': 'Response Time (ms)'}
        )
        fig.update_traces(
            line=dict(color='#00d4aa', width=3),
            mode='lines+markers'
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(color='white'),
            xaxis=dict(gridcolor='rgba(255,255,255,0.2)'),
            yaxis=dict(gridcolor='rgba(255,255,255,0.2)')
        )
    else:
        fig = go.Figure()
        fig.add_annotation(
            text="No performance data yet",
            xref="paper", yref="paper",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=20, color='white')
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
        )
    
    return fig

def create_session_stats_charts():
    """Create session statistics charts from run_app.py."""
    performance_stats = assistant.get_performance_stats()
    
    # Fast vs Slow queries gauge
    fast_rate = performance_stats.get("fast_response_rate", 0)
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = fast_rate,
        title = {'text': "Fast Response Rate (< 2s)"},
        domain = {'x': [0, 1], 'y': [0, 1]},
        gauge = {
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 50], 'color': "lightgray"},
                {'range': [50, 80], 'color': "gray"},
                {'range': [80, 100], 'color': "lightgreen"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 90
            }
        }
    ))
    
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white'),
        height=300
    )
    
    return fig

def create_enhanced_ui():
    """Create enhanced Gradio UI."""
    
    with gr.Blocks(
        theme=theme,
        css=custom_css,
        title="Enhanced AI Career Assistant - Venkatesh Narra"
    ) as demo:
        
        gr.HTML("""
        <div style="text-align: center; padding: 20px; background: rgba(255,255,255,0.1); border-radius: 15px; margin-bottom: 20px;">
            <h1 style="color: white; margin: 0;">üöÄ Enhanced AI Career Assistant</h1>
            <p style="color: rgba(255,255,255,0.8); margin: 10px 0 0 0;">Venkatesh Narra - Software Development Engineer</p>
        </div>
        """)
        
        with gr.Tabs() as tabs:
            
            # Chat Tab
            with gr.Tab("üí¨ AI Chat"):
                with gr.Row():
                    with gr.Column(scale=3):
                        chatbot = gr.Chatbot(
                            label="Enhanced AI Assistant",
                            height=600,
                            elem_classes=["chat-interface"],
                            type="messages"
                        )
                        
                        with gr.Row():
                            msg_input = gr.Textbox(
                                placeholder="Ask me about my skills, experience, projects, or anything else...",
                                container=False,
                                scale=4
                            )
                            submit_btn = gr.Button("Send", variant="primary", scale=1)
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(255,255,255,0.1); border-radius: 10px;">
                            <h4 style="color: white; margin: 0 0 10px 0;">üí° Try asking about:</h4>
                            <p style="color: rgba(255,255,255,0.8); margin: 5px 0;">‚Ä¢ My technical skills and frameworks</p>
                            <p style="color: rgba(255,255,255,0.8); margin: 5px 0;">‚Ä¢ Professional experience and achievements</p>
                            <p style="color: rgba(255,255,255,0.8); margin: 5px 0;">‚Ä¢ Projects I've built and technologies used</p>
                            <p style="color: rgba(255,255,255,0.8); margin: 5px 0;">‚Ä¢ Educational background and certifications</p>
                            <p style="color: rgba(255,255,255,0.8); margin: 5px 0;">‚Ä¢ Contact information and how to reach me</p>
                        </div>
                        """)
                    
                    with gr.Column(scale=1):
                        # Resume download section
                        gr.HTML("""
                        <div style="text-align: center; margin-bottom: 20px;">
                            <h3 style="color: white; margin: 0 0 10px 0;">üìÑ Resume</h3>
                        </div>
                        """)
                        
                        resume_file = create_resume_download_button()
                        
                        # Contact info section
                        gr.HTML(f"""
                        <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 15px; margin-top: 20px;">
                            <h3 style="color: white; margin: 0 0 15px 0;">üìû Contact</h3>
                            <p style="color: rgba(255,255,255,0.9); margin: 0;">üìß {PROFILE_DATA['email']}</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 0;">üì± {PROFILE_DATA['phone']}</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 0;">ÔøΩÔøΩ <a href="{PROFILE_DATA['linkedin']}" style="color: #00d4aa;">LinkedIn</a></p>
                            <p style="color: rgba(255,255,255,0.9); margin: 0;">üîó <a href="{PROFILE_DATA['github']}" style="color: #00d4aa;">GitHub</a></p>
                            <p style="color: rgba(255,255,255,0.9); margin: 0;">üìÖ <a href="{PROFILE_DATA['calendly']}" style="color: #00d4aa;">Schedule Meeting</a></p>
                        </div>
                        """)
                        
                        # Quick stats section
                        gr.HTML("""
                        <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 15px; margin-top: 20px;">
                            <h3 style="color: white; margin: 0 0 15px 0;">‚ö° Quick Stats</h3>
                            <p style="color: rgba(255,255,255,0.9); margin: 5px 0;">üéØ 4+ Years Experience</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 5px 0;">üöÄ 25K+ Daily API Inferences</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 5px 0;">‚ö° Sub-2s Response Times</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 5px 0;">üéì MS Computer Science</p>
                            <p style="color: rgba(255,255,255,0.9); margin: 5px 0;">üèÜ 99.9% System Uptime</p>
                        </div>
                        """)
            
            # Dashboard Tab
            with gr.Tab("üìä Dashboard"):
                with gr.Row():
                    # Analytics metrics
                    with gr.Column(scale=1):
                        metrics_html = gr.HTML(
                            value="""
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px;">
                                <div class="metric-card">
                                    <h3 style="color: white; margin: 0 0 10px 0;">üìà Total Queries</h3>
                                    <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">0</p>
                                </div>
                                <div class="metric-card">
                                    <h3 style="color: white; margin: 0 0 10px 0;">‚ö° Avg Response Time</h3>
                                    <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">0ms</p>
                                </div>
                                <div class="metric-card">
                                    <h3 style="color: white; margin: 0 0 10px 0;">‚úÖ Success Rate</h3>
                                    <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">100%</p>
                                </div>
                                <div class="metric-card">
                                    <h3 style="color: white; margin: 0 0 10px 0;">üîÑ System Status</h3>
                                    <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">üü¢ Online</p>
                                </div>
                            </div>
                            """,
                            elem_classes=["chart-container"]
                        )
                
                with gr.Row():
                    # Charts
                    with gr.Column(scale=1):
                        analytics_chart = gr.Plot(
                            value=create_analytics_chart(),
                            label="Query Distribution"
                        )
                    
                    with gr.Column(scale=1):
                        performance_chart = gr.Plot(
                            value=create_performance_chart(),
                            label="Performance Trend"
                        )
                
                # Session statistics from run_app.py
                with gr.Row():
                    with gr.Column(scale=1):
                        session_stats_chart = gr.Plot(
                            value=create_session_stats_charts(),
                            label="Session Statistics"
                        )
                
                # Refresh button
                refresh_btn = gr.Button("üîÑ Refresh Dashboard", variant="secondary")
                
                def refresh_dashboard():
                    """Refresh dashboard data."""
                    analytics = assistant.get_analytics_data()
                    
                    # Update metrics
                    metrics_html_new = f"""
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px;">
                        <div class="metric-card">
                            <h3 style="color: white; margin: 0 0 10px 0;">üìà Total Queries</h3>
                            <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">{analytics['total_queries']}</p>
                        </div>
                        <div class="metric-card">
                            <h3 style="color: white; margin: 0 0 10px 0;">‚ö° Avg Response Time</h3>
                            <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">{analytics['avg_response_time']:.0f}ms</p>
                        </div>
                        <div class="metric-card">
                            <h3 style="color: white; margin: 0 0 10px 0;">‚úÖ Success Rate</h3>
                            <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">{analytics['success_rate']}%</p>
                        </div>
                        <div class="metric-card">
                            <h3 style="color: white; margin: 0 0 10px 0;">üîÑ System Status</h3>
                            <p style="color: #00d4aa; font-size: 24px; font-weight: bold; margin: 0;">üü¢ Online</p>
                        </div>
                    </div>
                    """
                    
                    return (
                        metrics_html_new,
                        create_analytics_chart(),
                        create_performance_chart(),
                        create_session_stats_charts()
                    )
                
                refresh_btn.click(
                    refresh_dashboard,
                    outputs=[metrics_html, analytics_chart, performance_chart, session_stats_chart]
                )
            
            # Profile Tab
            with gr.Tab("üë§ Profile"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # Profile header
                        gr.HTML(f"""
                        <div class="profile-section">
                            <h2 style="color: white; margin: 0 0 20px 0;">üë§ Professional Profile</h2>
                            <div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
                                <div style="width: 80px; height: 80px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 32px;">
                                    üë®‚Äçüíª
                                </div>
                                <div>
                                    <h3 style="color: white; margin: 0 0 5px 0;">{PROFILE_DATA['name']}</h3>
                                    <p style="color: rgba(255,255,255,0.8); margin: 0 0 5px 0;">{PROFILE_DATA['title']}</p>
                                    <p style="color: rgba(255,255,255,0.7); margin: 0;">{PROFILE_DATA['company']} ‚Ä¢ {PROFILE_DATA['location']}</p>
                                </div>
                            </div>
                        </div>
                        """)
                        
                        # Skills section
                        skills_html = """
                        <div class="profile-section">
                            <h3 style="color: white; margin: 0 0 20px 0;">üõ†Ô∏è Technical Skills</h3>
                        """
                        
                        for category, skills in PROFILE_DATA['skills'].items():
                            skills_html += f"""
                            <div style="margin-bottom: 15px;">
                                <h4 style="color: rgba(255,255,255,0.9); margin: 0 0 8px 0; text-transform: capitalize;">{category.replace('_', ' & ')}</h4>
                                <div style="display: flex; flex-wrap: wrap; gap: 8px;">
                            """
                            for skill in skills:
                                skills_html += f"""
                                    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 20px; font-size: 14px;">{skill}</span>
                                """
                            skills_html += "</div></div>"
                        
                        skills_html += "</div>"
                        
                        gr.HTML(skills_html)
                    
                    with gr.Column(scale=1):
                        # Projects section
                        projects_html = """
                        <div class="profile-section">
                            <h3 style="color: white; margin: 0 0 20px 0;">üöÄ Featured Projects</h3>
                        """
                        
                        for project in PROFILE_DATA['projects']:
                            projects_html += f"""
                            <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                                <h4 style="color: white; margin: 0 0 10px 0;">{project['name']}</h4>
                                <p style="color: rgba(255,255,255,0.8); margin: 0 0 10px 0;">{project['description']}</p>
                                <div style="margin-bottom: 10px;">
                                    <strong style="color: rgba(255,255,255,0.9);">Technologies:</strong>
                                    <div style="display: flex; flex-wrap: wrap; gap: 5px; margin-top: 5px;">
                            """
                            for tech in project['technologies']:
                                projects_html += f"""
                                        <span style="background: rgba(0,212,170,0.2); color: #00d4aa; padding: 2px 8px; border-radius: 12px; font-size: 12px;">{tech}</span>
                                """
                            projects_html += """
                                    </div>
                                </div>
                                <div>
                                    <strong style="color: rgba(255,255,255,0.9);">Features:</strong>
                                    <ul style="margin: 5px 0 0 20px; color: rgba(255,255,255,0.8);">
                            """
                            for feature in project['features']:
                                projects_html += f"<li style='margin: 2px 0;'>{feature}</li>"
                            projects_html += """
                                    </ul>
                                </div>
                            </div>
                            """
                        
                        projects_html += "</div>"
                        
                        gr.HTML(projects_html)
            
            # Contact Tab
            with gr.Tab("üìß Contact"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.HTML("""
                        <div class="contact-form">
                            <h2 style="color: white; margin: 0 0 20px 0;">üìß Get in Touch</h2>
                            <p style="color: rgba(255,255,255,0.8); margin: 0 0 20px 0;">
                                I'm always open to discussing new opportunities, collaborations, or technical challenges. 
                                Feel free to reach out!
                            </p>
                        </div>
                        """)
                        
                        # Contact form
                        with gr.Group():
                            name_input = gr.Textbox(
                                label="Your Name",
                                placeholder="Enter your name...",
                                container=True
                            )
                            email_input = gr.Textbox(
                                label="Your Email",
                                placeholder="Enter your email...",
                                container=True
                            )
                            message_input = gr.Textbox(
                                label="Message",
                                placeholder="Enter your message...",
                                lines=5,
                                container=True
                            )
                            
                            submit_contact = gr.Button("Send Message", variant="primary")
                            contact_output = gr.HTML()
                        
                        def submit_contact_form(name, email, message):
                            """Handle contact form submission."""
                            if not name or not email or not message:
                                return "<div style='color: #ff6b6b; padding: 10px; background: rgba(255,107,107,0.1); border-radius: 5px;'>‚ùå Please fill in all fields</div>"
                            
                            # Here you would typically send the email or save to database
                            # For now, just return a success message
                            return f"""
                            <div style='color: #00d4aa; padding: 10px; background: rgba(0,212,170,0.1); border-radius: 5px;'>
                                ‚úÖ Thank you {name}! Your message has been sent. I'll get back to you soon at {email}.
                            </div>
                            """
                        
                        submit_contact.click(
                            submit_contact_form,
                            inputs=[name_input, email_input, message_input],
                            outputs=contact_output
                        )
                    
                    with gr.Column(scale=1):
                        # Direct contact info
                        gr.HTML(f"""
                        <div class="contact-form">
                            <h3 style="color: white; margin: 0 0 20px 0;">üìû Direct Contact</h3>
                            
                            <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                                <h4 style="color: white; margin: 0 0 15px 0;">üìß Email</h4>
                                <p style="color: rgba(255,255,255,0.9); margin: 0;">{PROFILE_DATA['email']}</p>
                                <a href="mailto:{PROFILE_DATA['email']}" style="color: #00d4aa; text-decoration: none;">‚úâÔ∏è Send Email</a>
                            </div>
                            
                            <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                                <h4 style="color: white; margin: 0 0 15px 0;">üì± Phone</h4>
                                <p style="color: rgba(255,255,255,0.9); margin: 0;">{PROFILE_DATA['phone']}</p>
                                <a href="tel:{PROFILE_DATA['phone']}" style="color: #00d4aa; text-decoration: none;">üìû Call Now</a>
                            </div>
                            
                            <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                                <h4 style="color: white; margin: 0 0 15px 0;">üíº Professional</h4>
                                <p style="color: rgba(255,255,255,0.9); margin: 0 0 10px 0;">
                                    <a href="{PROFILE_DATA['linkedin']}" style="color: #00d4aa; text-decoration: none;">üîó LinkedIn Profile</a>
                                </p>
                                <p style="color: rgba(255,255,255,0.9); margin: 0;">
                                    <a href="{PROFILE_DATA['github']}" style="color: #00d4aa; text-decoration: none;">üìÅ GitHub Portfolio</a>
                                </p>
                            </div>
                            
                            <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px;">
                                <h4 style="color: white; margin: 0 0 15px 0;">üìÖ Schedule Meeting</h4>
                                <p style="color: rgba(255,255,255,0.8); margin: 0 0 10px 0;">
                                    Book a convenient time to discuss opportunities or projects.
                                </p>
                                <a href="{PROFILE_DATA['calendly']}" target="_blank" style="color: #00d4aa; text-decoration: none;">üìÖ Schedule on Calendly</a>
                            </div>
                        </div>
                        """)
        
        # Footer
        gr.HTML("""
        <div class="footer">
            <p>¬© 2024 Venkatesh Narra - Enhanced AI Career Assistant</p>
            <p>Built with ‚ù§Ô∏è using Gradio, Python, and AI</p>
        </div>
        """)
        
        # Event handlers
        msg_input.submit(chat_interface, [msg_input, chatbot], [chatbot, msg_input])
        submit_btn.click(chat_interface, [msg_input, chatbot], [chatbot, msg_input])
    
    return demo

async def main():
    """Main application entry point."""
    logger.info("üöÄ Starting Enhanced Gradio UI...")
    
    # Initialize assistant
    await assistant.initialize()
    
    # Create and launch UI
    demo = create_enhanced_ui()
    
    # Launch configuration for production
    launch_config = {
        "server_name": "0.0.0.0",  # Listen on all interfaces for production
        "server_port": int(os.getenv("PORT", 7861)),  # Use PORT env var for cloud deployment
        "share": False,  # Set to True for temporary public links
        "show_error": True,
        "quiet": False
    }
    
    # Try to launch with automatic port finding if the default port is in use
    try:
        logger.info(f"üåê Launching on port {launch_config['server_port']}")
        demo.queue().launch(**launch_config)
    except OSError as e:
        if "Cannot find empty port" in str(e):
            logger.warning(f"‚ö†Ô∏è Port {launch_config['server_port']} is in use, trying alternative ports...")
            # Try ports 7862-7870 as alternatives
            for port in range(7862, 7871):
                try:
                    launch_config["server_port"] = port
                    logger.info(f"üåê Trying port {port}...")
                    demo.queue().launch(**launch_config)
                    break
                except OSError:
                    continue
            else:
                logger.error("‚ùå Could not find an available port. Please stop other instances or set a custom PORT environment variable.")
                raise
        else:
            raise

if __name__ == "__main__":
    print("""
üöÄ AI Career Assistant - Gradio UI
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

ü§ñ Multi-Agent System Architecture:
   1. Enhanced Smart Router (Gemini AI + Vector DB + Cache)
   2. MCP Agent (gRPC Career Assistant Server)  
   3. Enhanced Knowledge Base (Fallback Agent)

Features:
‚Ä¢ üìä Real-time analytics dashboard
‚Ä¢ üí¨ AI-powered chat with enhanced routing
‚Ä¢ üë§ Comprehensive profile display  
‚Ä¢ üìß Professional contact form
‚Ä¢ üìÖ Meeting scheduling integration
‚Ä¢ ‚ö° Sub-2-second response times
‚Ä¢ üöÄ Production-ready for cloud deployment

Ready for deployment to Render, Heroku, or any cloud platform!
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    """)
    
    asyncio.run(main()) 